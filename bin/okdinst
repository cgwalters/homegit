#!/usr/bin/python3

# Wraps openshift-installer with a more opinionated workflow around
# creating multiple clusters from a base template file.  See:
# https://github.com/openshift/installer/blob/master/docs/user/tips-and-tricks.md

import os,sys,json,yaml,shutil,argparse,subprocess,re,collections
import tempfile,hashlib,gzip

CONFIGDIR = os.path.expanduser('~/.config/openshift-install')
POSTSETUP = os.path.join(CONFIGDIR, "postsetup")
BASECONFIG = os.path.join(CONFIGDIR, "config.yaml")
CLUSTERSDIR = os.path.join(CONFIGDIR, "clusters")

def get_installer_config(basedir):
    with open(os.path.join(basedir, 'config.json')) as f:
        return json.load(f)

def mkdir_p(path):
    if not os.path.isdir(path):
        os.makedirs(path)

def rm_rf(path):
    if os.path.exists(path):
        shutil.rmtree(path)

def ensure_empty_dir(path):
    rm_rf(path)
    mkdir_p(path)

def run_installer(*args):
    local_binpath = os.path.join(os.getcwd(), "bin/openshift-install")
    if os.path.exists(local_binpath):
        binpath = local_binpath
    else:
        binpath = 'openshift-install'
    env = dict(os.environ)
    # https://github.com/openshift/installer/pull/785
    env['TF_VAR_libvirt_master_memory'] = '16384'
    env['TF_VAR_libvirt_master_vcpu'] = '4'
    subprocess.check_call([binpath] + list(args), env=env)

def ensure_base_config():
    if os.path.isfile(BASECONFIG):
        return
    print("Generating base configuration")
    tmpdir = os.path.join(CONFIGDIR, "tmp")
    ensure_empty_dir(tmpdir)
    run_installer('create', 'install-config', f'--dir={tmpdir}')
    os.rename(os.path.join(tmpdir, "install-config.yaml"), BASECONFIG)
    print(f"Generated base config: {BASECONFIG}")

def get_cluster_state(clusterdir):
    state_path = clusterdir + '/okdinst-state.json'
    if not os.path.exists(state_path):
        return None
    with open(state_path) as f:
        return json.load(f)['state']

def write_cluster_state(clusterdir, state):
    state_path = clusterdir + '/okdinst-state.json'
    with open(state_path + '.tmp', 'w') as f:
        json.dump({ "state": state }, f)
    os.rename(state_path + '.tmp', state_path)

def cmd_create(args):
    clusters = get_clusters()
    ensure_base_config()
    name = args.name
    clusterdir = os.path.join(CLUSTERSDIR, name)
    mkdir_p(clusterdir)
    state = get_cluster_state(clusterdir)
    if state == 'in-destruction':
        sys.exit(f"Cluster {name} was queued for destruction; rerun `destroy` first")
    elif state == 'created':
        sys.exit(f"Cluster {name} is already created")
    target_config = os.path.join(clusterdir, 'install-config.yaml')
    if not os.path.exists(target_config):
        with open(BASECONFIG) as f:
            config = yaml.load(f)
        config['metadata']['name'] = name
        libvirt = config['platform'].get('libvirt')
        if libvirt is not None:
            ifname = f'br-{name}'[0:14]
            print(f"Using libvirt NIC: {ifname}")
            libvirt['network']['if'] = ifname
            if args.libvirt_iprange:
                libvirt['network']['ipRange'] = args.libvirt_iprange
            #elif len(clusters) > 0:
            #    sys.exit("Already have a libvirt cluster defined, must specify --libvirt-iprange")
        with open(target_config, 'w') as f:
            yaml.dump(config, f)
        write_cluster_state(clusterdir, 'creating')
    else:
        print(f"Resuming installation of cluster {name}")
        write_cluster_state(clusterdir, 'resuming')
    run_installer("create", "cluster", "--dir", clusterdir)
    write_cluster_state(clusterdir, 'created')
    postsetup(name)
    write_cluster_state(clusterdir, 'configured')

def cmd_postsetup(args):
    postsetup(args.name)

def postsetup(name):
    clusterdir = os.path.join(CLUSTERSDIR, name)
    if os.path.isfile(POSTSETUP):
        env = dict(os.environ)
        env['KUBECONFIG'] = os.path.join(clusterdir, 'auth/kubeconfig')
        print(f"Running post-setup: {POSTSETUP}")
        subprocess.check_call([POSTSETUP], env=env)

def cmd_destroy(args):
    name = args.name
    clusterdir = os.path.join(CLUSTERSDIR, name)
    state = get_cluster_state(clusterdir)
    if state is None:
        sys.exit(f"No such cluster {name}")
    else:
        print(f"Destroying cluster '{name}' in state {state}")
    write_cluster_state(clusterdir, 'in-destruction')
    try:
        run_installer("destroy", "cluster", "--dir", clusterdir)
    except subprocess.CalledProcessError as e:
        if args.force:
            shutil.rmtree(clusterdir)
        else:
            raise
    shutil.rmtree(clusterdir)

def get_clusters():
    if not os.path.isdir(CLUSTERSDIR):
        children = []
    else:
        children = os.listdir(CLUSTERSDIR)
    r = {}
    for child in children:
        path = os.path.join(CLUSTERSDIR, child)
        if not os.path.isdir(path):
            continue
        r[child] = get_cluster_state(path)
    return r

def cmd_list(args):
    clusters = get_clusters()
    n = len(clusters)
    if n == 0:
        print("No clusters.")
        return
    print(f"Clusters:")
    for name,state in clusters.items():
        print(f"  {name}: {state}")

# Parse args and dispatch
parser = argparse.ArgumentParser()
subparsers = parser.add_subparsers(dest='action')
subparsers.required = True
parser_create = subparsers.add_parser('create')
parser_create.add_argument("name")
parser_create.add_argument("--libvirt-iprange", action='store')
parser_create.set_defaults(func=cmd_create)
parser_destroy = subparsers.add_parser('destroy')
parser_destroy.add_argument("name")
parser_destroy.add_argument("--force", action='store_true', help="Always remove cluster even if cleanup fails (may leak resources)")
parser_destroy.set_defaults(func=cmd_destroy)
parser_postsetup = subparsers.add_parser('postsetup')
parser_postsetup.add_argument("name")
parser_postsetup.set_defaults(func=cmd_postsetup)
parser_list = subparsers.add_parser('list')
parser_list.set_defaults(func=cmd_list)
args = parser.parse_args()
args.func(args)
